{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bab6afa",
   "metadata": {},
   "source": [
    "## 테스트 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19f45667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "from common.ResNet20 import ResNet20\n",
    "from common.functions import softmax  \n",
    "\n",
    "def download_cifar100(save_path='cifar-100-python'):\n",
    "    if os.path.exists(save_path):\n",
    "        print(\"CIFAR-100 이미 존재\")\n",
    "        return\n",
    "\n",
    "    url = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n",
    "    filename = 'cifar-100-python.tar.gz'\n",
    "    print(\"CIFAR-100 다운로드 중...\")\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "    with tarfile.open(filename, 'r:gz') as tar:\n",
    "        tar.extractall()\n",
    "    os.remove(filename)\n",
    "    print(\"다운로드 완료\")\n",
    "\n",
    "def load_batch(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data_dict = pickle.load(f, encoding='bytes')\n",
    "    data = data_dict[b'data']\n",
    "    fine_labels = np.array(data_dict[b'fine_labels'])\n",
    "    coarse_labels = np.array(data_dict[b'coarse_labels'])\n",
    "    data = data.reshape(-1, 3, 32, 32).astype(np.float32) / 255.0\n",
    "    return data, fine_labels, coarse_labels\n",
    "\n",
    "def load_cifar100_full(data_dir='./cifar-100-python', valid_ratio=0.1):\n",
    "    # 1. Load train and test batch\n",
    "    x_train_all, y_train_fine_all, y_train_coarse_all = load_batch(os.path.join(data_dir, 'train'))\n",
    "    x_test, y_test_fine, y_test_coarse = load_batch(os.path.join(data_dir, 'test'))\n",
    "\n",
    "    # 2. Split train → train + validation\n",
    "    num_total = x_train_all.shape[0]\n",
    "    num_valid = int(num_total * valid_ratio)\n",
    "\n",
    "    x_valid = x_train_all[:num_valid]\n",
    "    t_valid_fine = y_train_fine_all[:num_valid]\n",
    "    t_valid_coarse = y_train_coarse_all[:num_valid]\n",
    "\n",
    "    x_train = x_train_all[num_valid:]\n",
    "    t_train_fine = y_train_fine_all[num_valid:]\n",
    "    t_train_coarse = y_train_coarse_all[num_valid:]\n",
    "\n",
    "    # 3. Return all\n",
    "    return (x_train, x_valid, x_test,\n",
    "            t_train_coarse, t_valid_coarse, y_test_coarse,\n",
    "            t_train_fine, t_valid_fine, y_test_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a17de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100 이미 존재\n",
      "CIFAR-100 데이터셋 로드 완료:\n",
      " - x_train: (45000, 3, 32, 32)\n",
      " - x_valid: (5000, 3, 32, 32)\n",
      " - x_test : (10000, 3, 32, 32)\n",
      " - t_train_fine : (45000,)\n",
      " - t_valid_fine : (5000,)\n",
      " - t_test_fine  : (10000,)\n",
      " - t_train_coarse: (45000,)\n",
      " - t_valid_coarse: (5000,)\n",
      " - t_test_coarse : (10000,)\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-100 다운로드\n",
    "download_cifar100()\n",
    "\n",
    "# 전체 데이터셋 로드\n",
    "(x_train, x_valid, x_test,\n",
    " t_train_coarse, t_valid_coarse, t_test_coarse,\n",
    " t_train_fine, t_valid_fine, t_test_fine) = load_cifar100_full()\n",
    "\n",
    "# 확인 출력\n",
    "print(\"CIFAR-100 데이터셋 로드 완료:\")\n",
    "print(\" - x_train:\", x_train.shape)\n",
    "print(\" - x_valid:\", x_valid.shape)\n",
    "print(\" - x_test :\", x_test.shape)\n",
    "print(\" - t_train_fine :\", t_train_fine.shape)\n",
    "print(\" - t_valid_fine :\", t_valid_fine.shape)\n",
    "print(\" - t_test_fine  :\", t_test_fine.shape)\n",
    "print(\" - t_train_coarse:\", t_train_coarse.shape)\n",
    "print(\" - t_valid_coarse:\", t_valid_coarse.shape)\n",
    "print(\" - t_test_coarse :\", t_test_coarse.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2063c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model_parameters(model, model_state):\n",
    "    \n",
    "    model.conv1.W = model_state['conv1_W']\n",
    "    model.conv1.b = model_state['conv1_b']\n",
    "\n",
    "    model.fc.W = model_state['fc_W']\n",
    "    model.fc.b = model_state['fc_b']\n",
    "\n",
    "    idx = 0\n",
    "    for block in model.layer1 + model.layer2 + model.layer3:\n",
    "        for attr in ['conv1', 'conv2', 'shortcut']:\n",
    "            if hasattr(block, attr):\n",
    "                conv = getattr(block, attr)\n",
    "                conv.W = model_state[f'{idx}_W']\n",
    "                conv.b = model_state[f'{idx}_b']\n",
    "                idx += 1\n",
    "\n",
    "def restore_bn_params(model, state):\n",
    "    bn_count = 0\n",
    "    for block in model.layer1 + model.layer2 + model.layer3:\n",
    "        for attr in ['bn1', 'bn2']:\n",
    "            bn = getattr(block, attr)\n",
    "            bn.gamma = state[f'{bn_count}_gamma']\n",
    "            bn.beta = state[f'{bn_count}_beta']\n",
    "            bn.running_mean = state[f'{bn_count}_running_mean']\n",
    "            bn.running_var = state[f'{bn_count}_running_var']\n",
    "            bn_count += 1\n",
    "        if hasattr(block, 'bn_shortcut'):\n",
    "            bn = block.bn_shortcut\n",
    "            bn.gamma = state[f'{bn_count}_gamma']\n",
    "            bn.beta = state[f'{bn_count}_beta']\n",
    "            bn.running_mean = state[f'{bn_count}_running_mean']\n",
    "            bn.running_var = state[f'{bn_count}_running_var']\n",
    "            bn_count += 1\n",
    "\n",
    "    bn = model.bn1\n",
    "    bn.gamma = state[f'{bn_count}_gamma']\n",
    "    bn.beta = state[f'{bn_count}_beta']\n",
    "    bn.running_mean = state[f'{bn_count}_running_mean']\n",
    "    bn.running_var = state[f'{bn_count}_running_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99d0016-f1c2-485d-90ee-162d9331ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x, y_true):\n",
    "    batch_size = 100\n",
    "    preds = []\n",
    "    for i in range(0, x.shape[0], batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        logits = model.predict(x_batch)\n",
    "        probs = softmax(logits)\n",
    "        y_pred = np.argmax(probs, axis=1)\n",
    "        preds.append(y_pred)\n",
    "    preds = np.concatenate(preds)\n",
    "    acc = np.sum(preds == y_true) / len(y_true)\n",
    "    return preds, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d71e6b-8a05-474e-a212-6d741d62406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop model - [Fine Label] Valid Accuracy: 0.4826\n",
      "crop+flip model - [Fine Label] Valid Accuracy: 0.5061\n",
      "crop+flip+cutout model - [Fine Label] Valid Accuracy: 0.4944\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model_dir = \"final_parameters\"\n",
    "model_files = {\n",
    "    \"crop\": os.path.join(model_dir, \"crop_epoch_10.pkl\"),\n",
    "    \"crop+flip\": os.path.join(model_dir, \"crop+flip_epoch_10.pkl\"),\n",
    "    \"crop+flip+cutout\": os.path.join(model_dir, \"crop+flip+cutout_epoch_10.pkl\")\n",
    "}\n",
    "\n",
    "for name, file in model_files.items():\n",
    "    model = ResNet20()\n",
    "    with open(file, \"rb\") as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "        model_state = checkpoint[\"model\"]\n",
    "    restore_bn_params(model, model_state)\n",
    "    restore_model_parameters(model, model_state)\n",
    "    _, acc = evaluate_model(model, x_test, t_test_fine)\n",
    "    print(f\"{name} model - [Fine Label] Valid Accuracy: {acc:.4f}\")\n",
    "\n",
    "\n",
    "def predict_softmax(model, x):\n",
    "    batch_size = 100\n",
    "    probs = []\n",
    "    for i in range(0, x.shape[0], batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        logits = model.predict(x_batch)\n",
    "        prob = softmax(logits)\n",
    "        probs.append(prob)\n",
    "    return np.vstack(probs)\n",
    "    \n",
    "# 앙상블 softmax 예측\n",
    "probs_list = []\n",
    "\n",
    "for name, file in model_files.items():\n",
    "    model = ResNet20()\n",
    "    with open(file, \"rb\") as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "        model_state = checkpoint[\"model\"]\n",
    "    restore_bn_params(model, model_state)\n",
    "    restore_model_parameters(model, model_state)\n",
    "    probs = predict_softmax(model, x_test)\n",
    "    probs_list.append(probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56b6b38-d73a-4aa5-a022-8b6cd71b2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar100_fine_to_coarse_dict():\n",
    "    \"\"\"\n",
    "    CIFAR-100 공식 fine label (0~99) → coarse label (0~19) 매핑 딕셔너리\n",
    "    \"\"\"\n",
    "    fine_to_coarse = {\n",
    "         4: 0, 30: 0, 55: 0, 72: 0, 95: 0,     # aquatic mammals\n",
    "         1: 1, 32: 1, 67: 1, 73: 1, 91: 1,     # fish\n",
    "        54: 2, 62: 2, 70: 2, 82: 2, 92: 2,     # flowers\n",
    "        9: 3, 10: 3, 16: 3, 28: 3, 61: 3,      # food containers\n",
    "         0: 4, 51: 4, 53: 4, 57: 4, 83: 4,     # fruit and vegetables\n",
    "        22: 5, 39: 5, 40: 5, 86: 5, 87: 5,     # household electrical devices\n",
    "         5: 6, 20: 6, 25: 6, 84: 6, 94: 6,     # household furniture\n",
    "         6: 7, 7: 7, 14: 7, 18: 7, 24: 7,      # insects\n",
    "        3: 8, 42: 8, 43: 8, 88: 8, 97: 8,      # large carnivores\n",
    "        12: 9, 17: 9, 37: 9, 68: 9, 76: 9,     # large man-made outdoor things\n",
    "        23:10, 33:10, 49:10, 60:10, 71:10,     # large natural outdoor scenes\n",
    "        15:11, 19:11, 21:11, 31:11, 38:11,     # medium-sized mammals\n",
    "        34:12, 63:12, 64:12, 66:12, 75:12,     # non-insect invertebrates\n",
    "        26:13, 45:13, 77:13, 79:13, 99:13,     # people\n",
    "         2:14, 11:14, 35:14, 46:14, 98:14,     # reptiles\n",
    "         27:15, 29:15, 44:15, 78:15, 93:15,    # small mammals\n",
    "         36:16, 50:16, 65:16, 74:16, 80:16,    # trees\n",
    "         8:17, 13:17, 48:17, 58:17, 90:17,     # vehicles 1\n",
    "        41:18, 52:18, 56:18, 59:18, 96:18,     # vehicles 2\n",
    "        47:19, 69:19, 81:19, 85:19, 89:19      # objects\n",
    "    }\n",
    "    return fine_to_coarse\n",
    "\n",
    "\n",
    "\n",
    "def map_softmax_to_coarse(softmax_output, fine_to_coarse):\n",
    "    \"\"\"\n",
    "    softmax_output: shape (N, 100), softmax 확률 결과\n",
    "    fine_to_coarse: dict, fine label → coarse label 매핑\n",
    "    \n",
    "    return: pred_coarse: shape (N,), coarse label 예측 결과\n",
    "    \"\"\"\n",
    "    fine_pred = np.argmax(softmax_output, axis=1)  # shape (N,)\n",
    "    coarse_pred = np.array([fine_to_coarse[f] for f in fine_pred])  # shape (N,)\n",
    "    return coarse_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155a47be-46fe-4b9e-8524-5231757113ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fine Label] Ensemble Valid Accuracy: 0.5750\n",
      "[Coarse Label] Ensemble Accuracy: 0.6077\n"
     ]
    }
   ],
   "source": [
    "# softmax 평균 앙상블\n",
    "ensemble_probs = np.mean(probs_list, axis=0)\n",
    "ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "ensemble_acc = np.sum(ensemble_preds == t_test_fine) / len(t_test_fine)\n",
    "print(f\"[Fine Label] Ensemble Valid Accuracy: {ensemble_acc:.4f}\")\n",
    "\n",
    "\n",
    "#단순 매핑 추가\n",
    "fine_to_coarse = get_cifar100_fine_to_coarse_dict()\n",
    "ensemble_preds_coarse = map_softmax_to_coarse(ensemble_probs, fine_to_coarse)\n",
    "ensemble_coarse_acc = np.mean(ensemble_preds_coarse == t_test_coarse)\n",
    "print(f\"[Coarse Label] Ensemble Accuracy: {ensemble_coarse_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9762d973-2d2f-4351-b07f-b8ff34e86c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fine Label] Weighted Ensemble Accuracy: 0.5688\n",
      "[Coarse Label] Weighted Ensemble Accuracy: 0.6017\n"
     ]
    }
   ],
   "source": [
    "# 가중 평균 앙상블 (Weighted Average Ensemble)\n",
    "weights = {\n",
    "    \"crop\": 0.2,\n",
    "    \"crop+flip\": 0.5,\n",
    "    \"crop+flip+cutout\": 0.3\n",
    "}\n",
    "\n",
    "probs_list = []\n",
    "for name, file in model_files.items():\n",
    "    model = ResNet20()\n",
    "    with open(file, \"rb\") as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "        model_state = checkpoint[\"model\"]\n",
    "    restore_bn_params(model, model_state)\n",
    "    restore_model_parameters(model, model_state)\n",
    "    probs = predict_softmax(model, x_test)\n",
    "    probs_list.append(weights[name] * probs)\n",
    "\n",
    "ensemble_probs = np.sum(probs_list, axis=0)\n",
    "ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "ensemble_acc = np.sum(ensemble_preds == t_test_fine) / len(t_test_fine)\n",
    "print(f\"[Fine Label] Weighted Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
    "\n",
    "\n",
    "#단순 매핑 추가\n",
    "fine_to_coarse = get_cifar100_fine_to_coarse_dict()\n",
    "ensemble_preds_coarse = map_softmax_to_coarse(ensemble_probs, fine_to_coarse)\n",
    "ensemble_coarse_acc = np.mean(ensemble_preds_coarse == t_test_coarse)\n",
    "print(f\"[Coarse Label] Weighted Ensemble Accuracy: {ensemble_coarse_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6693bff5-d30f-4ff9-963e-605893babd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fine Label] Logit Averaging Ensemble Accuracy: 0.5796\n",
      "[Coarse Label] Weighted Ensemble Accuracy: 0.6160\n"
     ]
    }
   ],
   "source": [
    "# 로그 소프트맥스 평균 (Logit Averaging Ensemble)\n",
    "\n",
    "def predict_logits(model, x):\n",
    "    batch_size = 100\n",
    "    logits_all = []\n",
    "    for i in range(0, x.shape[0], batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        logits = model.predict(x_batch)\n",
    "        logits_all.append(logits)\n",
    "    return np.vstack(logits_all)\n",
    "\n",
    "logits_list = []\n",
    "for name, file in model_files.items():\n",
    "    model = ResNet20()\n",
    "    with open(file, \"rb\") as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "        model_state = checkpoint[\"model\"]\n",
    "    restore_bn_params(model, model_state)\n",
    "    restore_model_parameters(model, model_state)\n",
    "    logits = predict_logits(model, x_test)\n",
    "    logits_list.append(logits)\n",
    "\n",
    "ensemble_logits = np.mean(logits_list, axis=0)\n",
    "ensemble_probs = softmax(ensemble_logits)\n",
    "ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "ensemble_acc = np.sum(ensemble_preds == t_test_fine) / len(t_test_fine)\n",
    "print(f\"[Fine Label] Logit Averaging Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
    "\n",
    "#단순 매핑 추가\n",
    "fine_to_coarse = get_cifar100_fine_to_coarse_dict()\n",
    "ensemble_preds_coarse = map_softmax_to_coarse(ensemble_probs, fine_to_coarse)\n",
    "ensemble_coarse_acc = np.mean(ensemble_preds_coarse == t_test_coarse)\n",
    "print(f\"[Coarse Label] Weighted Ensemble Accuracy: {ensemble_coarse_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f6fae-f226-46e7-8daa-81a239c2d8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f46949-5116-4619-b2bb-d7efa9d5a837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
