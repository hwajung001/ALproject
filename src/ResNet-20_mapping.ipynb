{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-100 다운로드 및 로딩\n",
    "from common.util import shuffle_dataset\n",
    "import pickle, os\n",
    "import numpy as np\n",
    "\n",
    "def load_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "    return data[b'data'], np.array(data[b'fine_labels']), np.array(data[b'coarse_labels'])\n",
    "\n",
    "def normalize(x):\n",
    "    mean = np.array([0.507, 0.487, 0.441]).reshape(1, 3, 1, 1)\n",
    "    std = np.array([0.267, 0.256, 0.276]).reshape(1, 3, 1, 1)\n",
    "    return (x - mean) / std\n",
    "\n",
    "def load_cifar100():\n",
    "    x_train, y_train_fine, y_train_coarse = load_batch(\"./cifar-100-python/train\")\n",
    "    x_test, y_test_fine, y_test_coarse = load_batch(\"./cifar-100-python/test\")\n",
    "    x_test = x_test.reshape(-1, 3, 32, 32).astype(np.float32) / 255.0\n",
    "    x_test = normalize(x_test)\n",
    "    return x_test, y_test_fine, y_test_coarse\n",
    "\n",
    "x_test, y_test_fine, y_test_coarse = load_cifar100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_normalized_fine_to_coarse_matrix(fine_labels, coarse_labels, num_fine=100, num_coarse=20):\n",
    "    count = np.zeros((num_fine, num_coarse), dtype=np.float32)\n",
    "    for fine, coarse in zip(fine_labels, coarse_labels):\n",
    "        count[fine, coarse] += 1\n",
    "    row_sums = np.sum(count, axis=1, keepdims=True)\n",
    "    row_sums[row_sums == 0] = 1  # 방어적 처리\n",
    "    return count / row_sums  # normalize to soft weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train에서 label 관계 추출\n",
    "_, y_train_fine, y_train_coarse = load_batch(\"./cifar-100-python/train\")\n",
    "mapping_matrix = create_normalized_fine_to_coarse_matrix(y_train_fine, y_train_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "from common.layers import Convolution, Affine, Relu, BatchNormalization\n",
    "from common.util import im2col, col2im\n",
    "\n",
    "# --- Affine (양자화 제거) ---\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "        return out\n",
    "\n",
    "# --- Convolution (양자화 제거) ---\n",
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.x = None\n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, _, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "# --- Residual Block ---\n",
    "class ResidualBlock:\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        self.stride = stride\n",
    "        self.equal_in_out = (in_channels == out_channels and stride == 1)\n",
    "\n",
    "        self.conv1 = Convolution(np.random.randn(out_channels, in_channels, 3, 3), np.zeros(out_channels), stride=stride, pad=1)\n",
    "        self.bn1 = BatchNormalization(np.ones(out_channels), np.zeros(out_channels))\n",
    "        self.relu1 = Relu()\n",
    "\n",
    "        self.conv2 = Convolution(np.random.randn(out_channels, out_channels, 3, 3), np.zeros(out_channels), stride=1, pad=1)\n",
    "        self.bn2 = BatchNormalization(np.ones(out_channels), np.zeros(out_channels))\n",
    "        self.relu2 = Relu()\n",
    "\n",
    "        if not self.equal_in_out:\n",
    "            self.shortcut = Convolution(np.random.randn(out_channels, in_channels, 1, 1), np.zeros(out_channels), stride=stride, pad=0)\n",
    "            self.bn_shortcut = BatchNormalization(np.ones(out_channels), np.zeros(out_channels))\n",
    "\n",
    "    def forward(self, x, train_flg=False):\n",
    "        out = self.relu1.forward(self.bn1.forward(self.conv1.forward(x), train_flg))\n",
    "        out = self.bn2.forward(self.conv2.forward(out), train_flg)\n",
    "\n",
    "        shortcut = x if self.equal_in_out else self.bn_shortcut.forward(self.shortcut.forward(x), train_flg)\n",
    "        out += shortcut\n",
    "        return self.relu2.forward(out)\n",
    "\n",
    "# --- ResNet-20 ---\n",
    "class ResNet20:\n",
    "    def __init__(self, num_classes=100):\n",
    "        self.conv1 = Convolution(np.random.randn(16, 3, 3, 3), np.zeros(16), stride=1, pad=1)\n",
    "        self.bn1 = BatchNormalization(np.ones(16), np.zeros(16))\n",
    "        self.relu1 = Relu()\n",
    "\n",
    "        self.layer1 = [ResidualBlock(16, 16, stride=1) for _ in range(3)]\n",
    "        self.layer2 = [ResidualBlock(16 if i == 0 else 32, 32, stride=2 if i == 0 else 1) for i in range(3)]\n",
    "        self.layer3 = [ResidualBlock(32 if i == 0 else 64, 64, stride=2 if i == 0 else 1) for i in range(3)]\n",
    "\n",
    "        self.fc = Affine(np.random.randn(64, num_classes), np.zeros(num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1.forward(self.bn1.forward(self.conv1.forward(x), train_flg=False))\n",
    "        for block in self.layer1: out = block.forward(out)\n",
    "        for block in self.layer2: out = block.forward(out)\n",
    "        for block in self.layer3: out = block.forward(out)\n",
    "\n",
    "        out = out.mean(axis=(2, 3))  # Global Average Pooling\n",
    "        return self.fc.forward(out)\n",
    "\n",
    "    def predict(self, x, batch_size=100):\n",
    "        return np.concatenate([self.forward(x[i:i+batch_size]) for i in range(0, x.shape[0], batch_size)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.functions import softmax\n",
    "\n",
    "# 저장된 모델 불러오기\n",
    "with open(\"ANN_Generalized/ResNet20_cfg1_smooth0.05_epoch_10.pkl\", 'rb') as f:\n",
    "    model_data = pickle.load(f)\n",
    "\n",
    "model = ResNet20()\n",
    "\n",
    "# 저장된 weight 불러오기\n",
    "param_dict = model_data['model']\n",
    "idx = 0\n",
    "for layer in model.layer1 + model.layer2 + model.layer3:\n",
    "    for attr in ['conv1', 'conv2', 'shortcut']:\n",
    "        if hasattr(layer, attr) and f\"{idx}_W\" in param_dict:\n",
    "            conv = getattr(layer, attr)\n",
    "            conv.W = param_dict[f\"{idx}_W\"]\n",
    "            conv.b = param_dict[f\"{idx}_b\"]\n",
    "            idx += 1\n",
    "model.fc.W = param_dict['fc_W']\n",
    "model.fc.b = param_dict['fc_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coarse_accuracy(model, x, y_coarse, mapping_matrix, batch_size=100):\n",
    "    correct = 0\n",
    "    total = x.shape[0]\n",
    "\n",
    "    for i in range(0, total, batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        y_batch = y_coarse[i:i+batch_size]\n",
    "\n",
    "        fine_logits = model.predict(x_batch)  # (N, 100)\n",
    "        fine_probs = softmax(fine_logits)     # (N, 100)\n",
    "\n",
    "        coarse_probs = np.dot(fine_probs, mapping_matrix)  # (N, 20)\n",
    "        pred_coarse = np.argmax(coarse_probs, axis=1)\n",
    "\n",
    "        correct += np.sum(pred_coarse == y_batch)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Coarse label accuracy: 0.0505\n"
     ]
    }
   ],
   "source": [
    "coarse_acc = compute_coarse_accuracy(model, x_test, y_test_coarse, mapping_matrix)\n",
    "print(f\"Coarse label accuracy: {coarse_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fine_to_coarse_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m fine_logits = model.predict(x_test)\n\u001b[32m      2\u001b[39m fine_logits -= np.max(fine_logits, axis=\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# overflow 방지\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m coarse_logits = fine_logits @ \u001b[43mfine_to_coarse_matrix\u001b[49m\n\u001b[32m      4\u001b[39m coarse_probs = softmax(coarse_logits)\n\u001b[32m      5\u001b[39m coarse_preds = np.argmax(coarse_probs, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'fine_to_coarse_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "fine_logits = model.predict(x_test)\n",
    "fine_logits -= np.max(fine_logits, axis=1, keepdims=True)  # overflow 방지\n",
    "coarse_logits = fine_logits @ fine_to_coarse_matrix\n",
    "coarse_probs = softmax(coarse_logits)\n",
    "coarse_preds = np.argmax(coarse_probs, axis=1)\n",
    "accuracy = np.mean(coarse_preds == y_test_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from common.functions import softmax\n",
    "\n",
    "# 1. CIFAR-100 coarse 라벨 메타 정보 불러오기\n",
    "def load_meta(data_dir=\"./cifar-100-python\"):\n",
    "    with open(f\"{data_dir}/meta\", 'rb') as f:\n",
    "        meta = pickle.load(f, encoding='bytes')\n",
    "        return meta[b'fine_label_names'], meta[b'coarse_label_names']\n",
    "\n",
    "# 2. CIFAR-100 test 데이터 로딩\n",
    "def load_cifar100_test(data_dir=\"./cifar-100-python\"):\n",
    "    with open(f\"{data_dir}/test\", 'rb') as f:\n",
    "        batch = pickle.load(f, encoding='bytes')\n",
    "    x = batch[b'data'].reshape(-1, 3, 32, 32).astype(np.float32) / 255.0\n",
    "    mean = np.array([0.507, 0.487, 0.441]).reshape(1, 3, 1, 1)\n",
    "    std = np.array([0.267, 0.256, 0.276]).reshape(1, 3, 1, 1)\n",
    "    x = (x - mean) / std\n",
    "    y_fine = np.array(batch[b'fine_labels'])\n",
    "    y_coarse = np.array(batch[b'coarse_labels'])\n",
    "    return x, y_fine, y_coarse\n",
    "\n",
    "# 3. fine → coarse 매핑 행렬 생성\n",
    "# 100개 fine label → 20개 coarse label 매핑 행렬 생성\n",
    "def create_fine_to_coarse_matrix_from_meta(meta_path=\"./cifar-100-python/train\", num_fine=100, num_coarse=20):\n",
    "    with open(meta_path, 'rb') as f:\n",
    "        batch = pickle.load(f, encoding='bytes')\n",
    "        fine_labels = batch[b'fine_labels']\n",
    "        coarse_labels = batch[b'coarse_labels']\n",
    "\n",
    "    mapping = np.zeros((num_fine, num_coarse), dtype=np.float32)\n",
    "    for fine, coarse in zip(fine_labels, coarse_labels):\n",
    "        mapping[fine, coarse] = 1.0\n",
    "\n",
    "    return mapping\n",
    "\n",
    "# 4. 저장된 모델 파라미터 로드 & 적용\n",
    "def load_weights_into_model(model, pkl_path):\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    weights = data['model']\n",
    "    \n",
    "    # fc layer\n",
    "    model.fc.W = weights['fc_W']\n",
    "    model.fc.b = weights['fc_b']\n",
    "\n",
    "    # conv layers\n",
    "    conv_layers = (\n",
    "        model.layer1 + model.layer2 + model.layer3\n",
    "    )\n",
    "    i = 0\n",
    "    for layer in conv_layers:\n",
    "        for conv_name in ['conv1', 'conv2']:\n",
    "            conv = getattr(layer, conv_name)\n",
    "            conv.W = weights[f'{i}_W']\n",
    "            conv.b = weights[f'{i}_b']\n",
    "            i += 1\n",
    "        if hasattr(layer, 'shortcut'):\n",
    "            layer.shortcut.W = weights[f'{i}_W']\n",
    "            layer.shortcut.b = weights[f'{i}_b']\n",
    "            i += 1\n",
    "    print(\"✅ Model weights loaded.\")\n",
    "\n",
    "# 5. 추론 및 coarse accuracy 계산\n",
    "def evaluate_coarse_accuracy(model, x_test, y_coarse, fine_to_coarse_mat):\n",
    "    batch_size = 100\n",
    "    correct = 0\n",
    "    total = x_test.shape[0]\n",
    "\n",
    "    for i in range(0, total, batch_size):\n",
    "        x_batch = x_test[i:i+batch_size]\n",
    "        y_batch = y_coarse[i:i+batch_size]\n",
    "\n",
    "        # logits: (B, 100)\n",
    "        fine_logits = model.predict(x_batch)\n",
    "        fine_logits -= np.max(fine_logits, axis=1, keepdims=True)  # stability\n",
    "        coarse_logits = fine_logits @ fine_to_coarse_mat  # (B, 20)\n",
    "        coarse_probs = softmax(coarse_logits)\n",
    "        coarse_preds = np.argmax(coarse_probs, axis=1)\n",
    "\n",
    "        correct += np.sum(coarse_preds == y_batch)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"✅ Coarse Accuracy: {acc:.4f}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model weights loaded.\n",
      "✅ Coarse Accuracy: 0.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.05)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test, y_fine, y_coarse = load_cifar100_test()\n",
    "fine_names, coarse_names = load_meta()\n",
    "fine_to_coarse = create_fine_to_coarse_matrix_from_meta()\n",
    "\n",
    "model = ResNet20(num_classes=100)\n",
    "load_weights_into_model(model, \"ANN_Generalized/ResNet20_cfg1_smooth0.05_epoch_10.pkl\")\n",
    "\n",
    "evaluate_coarse_accuracy(model, x_test, y_coarse, fine_to_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
