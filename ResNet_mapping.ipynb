{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e950ddbd-4849-404b-b353-18dba24c522d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## import, plk 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7052c4-eb40-4c6d-b07f-46c7f8c0b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "## 모델에 필요한거\n",
    "import numpy as np\n",
    "from common.layers import Convolution, Affine, Relu, BatchNormalization\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.util import im2col, col2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db77cc7e-a1aa-4f01-9862-9dc2e93e07c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['model', 'optimizer'])\n",
      "<class 'dict'>\n",
      "['fc_W', 'fc_b', '0_W', '0_b', '1_W', '1_b', '2_W', '2_b', '3_W', '3_b']\n",
      "fc_W: (64, 100)\n",
      "fc_b: (100,)\n",
      "0_W: (16, 16, 3, 3)\n",
      "0_b: (16,)\n",
      "1_W: (16, 16, 3, 3)\n",
      "1_b: (16,)\n",
      "2_W: (16, 16, 3, 3)\n",
      "2_b: (16,)\n",
      "3_W: (16, 16, 3, 3)\n",
      "3_b: (16,)\n",
      "4_W: (16, 16, 3, 3)\n",
      "4_b: (16,)\n",
      "5_W: (16, 16, 3, 3)\n",
      "5_b: (16,)\n",
      "6_W: (32, 16, 3, 3)\n",
      "6_b: (32,)\n",
      "7_W: (32, 32, 3, 3)\n",
      "7_b: (32,)\n",
      "8_W: (32, 16, 1, 1)\n",
      "8_b: (32,)\n",
      "9_W: (32, 32, 3, 3)\n",
      "9_b: (32,)\n",
      "10_W: (32, 32, 3, 3)\n",
      "10_b: (32,)\n",
      "11_W: (32, 32, 3, 3)\n",
      "11_b: (32,)\n",
      "12_W: (32, 32, 3, 3)\n",
      "12_b: (32,)\n",
      "13_W: (64, 32, 3, 3)\n",
      "13_b: (64,)\n",
      "14_W: (64, 64, 3, 3)\n",
      "14_b: (64,)\n",
      "15_W: (64, 32, 1, 1)\n",
      "15_b: (64,)\n",
      "16_W: (64, 64, 3, 3)\n",
      "16_b: (64,)\n",
      "17_W: (64, 64, 3, 3)\n",
      "17_b: (64,)\n",
      "18_W: (64, 64, 3, 3)\n",
      "18_b: (64,)\n",
      "19_W: (64, 64, 3, 3)\n",
      "19_b: (64,)\n"
     ]
    }
   ],
   "source": [
    "# .pkl 구조 확인\n",
    "import pickle\n",
    "\n",
    "with open(\"Resnet-20_epoch30_model.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# 1. 최상위 타입 및 키\n",
    "print(type(data))           # dict expected\n",
    "print(data.keys())          # ['model', 'optimizer']\n",
    "\n",
    "# 2. 모델 파라미터 키 목록\n",
    "model = data['model']\n",
    "print(type(model))          # dict expected\n",
    "print(list(model.keys())[:10])  # ['fc_W', 'fc_b', '0_W', ...]\n",
    "\n",
    "# 3. 파라미터 shape 확인\n",
    "for k in model.keys():\n",
    "    print(f\"{k}: {model[k].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e4b90a-ce58-46fc-9d09-dd864582150d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['model', 'optimizer'])\n",
      "dict_keys(['fc_W', 'fc_b', '0_W', '0_b', '1_W', '1_b', '2_W', '2_b', '3_W', '3_b', '4_W', '4_b', '5_W', '5_b', '6_W', '6_b', '7_W', '7_b', '8_W', '8_b', '9_W', '9_b', '10_W', '10_b', '11_W', '11_b', '12_W', '12_b', '13_W', '13_b', '14_W', '14_b', '15_W', '15_b', '16_W', '16_b', '17_W', '17_b', '18_W', '18_b', '19_W', '19_b'])\n"
     ]
    }
   ],
   "source": [
    "with open('Resnet-20_epoch30_model.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(type(data))         # dict여야 함\n",
    "print(data.keys())        # model, optimizer\n",
    "print(data['model'].keys())  # 0_W ~ 19_W, fc_W, fc_b 있어야 함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b68e7a5-f86e-4ab2-bc44-1d86372d9f52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13777468-f6ae-44d4-b0f9-7c448b9026fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드 및 전처리\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "def download_cifar100(dest=\"./cifar-100-python\"):\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    \n",
    "    def is_within_directory(directory, target):\n",
    "        abs_directory = os.path.abspath(directory)\n",
    "        abs_target = os.path.abspath(target)\n",
    "        return os.path.commonprefix([abs_directory, abs_target]) == abs_directory\n",
    "\n",
    "    def safe_extract(tar, path=\".\", members=None):\n",
    "        for member in tar.getmembers():\n",
    "            member_path = os.path.join(path, member.name)\n",
    "            if not is_within_directory(path, member_path):\n",
    "                raise Exception(\"Attempted Path Traversal in Tar File\")\n",
    "        tar.extractall(path, members)\n",
    "\n",
    "    if not os.path.exists(dest):\n",
    "        os.makedirs(dest, exist_ok=True)\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        with tarfile.open(filename, \"r:gz\") as tar:\n",
    "            safe_extract(tar, path=\"./\")\n",
    "        print(\"CIFAR-100 downloaded and extracted.\")\n",
    "    else:\n",
    "        print(\"CIFAR-100 already downloaded.\")\n",
    "\n",
    "def load_cifar100(data_dir=\"./cifar-100-python\"):\n",
    "    def load_batch(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            dict = pickle.load(f, encoding='bytes')\n",
    "            data = dict[b'data']\n",
    "            labels = dict[b'fine_labels']\n",
    "            coarse_labels = dict[b'coarse_labels']\n",
    "            return data, labels, coarse_labels\n",
    "\n",
    "    x_train, y_train, y_train_coarse = load_batch(os.path.join(data_dir, \"train\"))\n",
    "    x_test, y_test, y_test_coarse = load_batch(os.path.join(data_dir, \"test\"))\n",
    "\n",
    "    x_train = x_train.reshape(-1, 3, 32, 32).astype(np.float32) / 255.0\n",
    "    x_test = x_test.reshape(-1, 3, 32, 32).astype(np.float32) / 255.0\n",
    "\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    y_train_coarse = np.array(y_train_coarse)\n",
    "    y_test_coarse = np.array(y_test_coarse)\n",
    "\n",
    "    val_size = int(0.1 * len(x_train))\n",
    "    x_val = x_train[:val_size]\n",
    "    y_val = y_train[:val_size]\n",
    "    x_train = x_train[val_size:]\n",
    "    y_train = y_train[val_size:]\n",
    "\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test), (y_train_coarse, y_test_coarse) # 지금 y_valid_coarse가 없는거지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "441fbdb4-8cb4-4369-8426-b7f522e631c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100 already downloaded.\n",
      " CIFAR-100 Dataset Loaded!\n",
      "Train X shape: (45000, 3, 32, 32), Train Y shape: (45000,)\n",
      "Val   X shape: (5000, 3, 32, 32), Val   Y shape: (5000,)\n",
      "Test  X shape: (10000, 3, 32, 32), Test  Y shape: (10000,)\n",
      "Coarse Labels - Train: (50000,), Test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 다운로드 및 로딩\n",
    "download_cifar100()\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test), (y_train_coarse, y_test_coarse) = load_cifar100()\n",
    "\n",
    "# 데이터셋 정보 출력\n",
    "print(\" CIFAR-100 Dataset Loaded!\")\n",
    "print(f\"Train X shape: {x_train.shape}, Train Y shape: {y_train.shape}\")\n",
    "print(f\"Val   X shape: {x_val.shape}, Val   Y shape: {y_val.shape}\")\n",
    "print(f\"Test  X shape: {x_test.shape}, Test  Y shape: {y_test.shape}\")\n",
    "print(f\"Coarse Labels - Train: {y_train_coarse.shape}, Test: {y_test_coarse.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc62c396-ffad-46d1-8b95-742fa7f9ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 변수명 정리를 해야하나?\n",
    "## 노노 일단 test 에 대해서만 할거니까 \n",
    "##나중에 필요하면 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d42f0-6c63-43b5-aa9e-4dbd169e8902",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 서아 모델 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af345a97-6fa6-4ae9-a198-89a579093430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock:\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        self.stride = stride\n",
    "        self.equal_in_out = (in_channels == out_channels and stride == 1)\n",
    "\n",
    "        self.conv1 = Convolution(\n",
    "            W=np.random.randn(out_channels, in_channels, 3, 3) * np.sqrt(2. / in_channels),\n",
    "            b=np.zeros(out_channels),\n",
    "            stride=stride,\n",
    "            pad=1\n",
    "        )\n",
    "        self.bn1 = BatchNormalization(gamma=np.ones(out_channels), beta=np.zeros(out_channels))\n",
    "        self.relu1 = Relu()\n",
    "\n",
    "        self.conv2 = Convolution(\n",
    "            W=np.random.randn(out_channels, out_channels, 3, 3) * np.sqrt(2. / out_channels),\n",
    "            b=np.zeros(out_channels),\n",
    "            stride=1,\n",
    "            pad=1\n",
    "        )\n",
    "        self.bn2 = BatchNormalization(gamma=np.ones(out_channels), beta=np.zeros(out_channels))\n",
    "        self.relu2 = Relu()\n",
    "\n",
    "        if not self.equal_in_out:\n",
    "            self.shortcut = Convolution(\n",
    "                W=np.random.randn(out_channels, in_channels, 1, 1) * np.sqrt(2. / in_channels),\n",
    "                b=np.zeros(out_channels),\n",
    "                stride=stride,\n",
    "                pad=0\n",
    "            )\n",
    "            self.bn_shortcut = BatchNormalization(gamma=np.ones(out_channels), beta=np.zeros(out_channels))\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        self.x = x\n",
    "\n",
    "        out = self.conv1.forward(x)\n",
    "        out = self.bn1.forward(out, train_flg)\n",
    "        out = self.relu1.forward(out)\n",
    "\n",
    "        out = self.conv2.forward(out)\n",
    "        out = self.bn2.forward(out, train_flg)\n",
    "        self.out_main = out\n",
    "\n",
    "        if self.equal_in_out:\n",
    "            shortcut = x\n",
    "        else:\n",
    "            shortcut = self.shortcut.forward(x)\n",
    "            shortcut = self.bn_shortcut.forward(shortcut, train_flg)\n",
    "        self.out_shortcut = shortcut\n",
    "\n",
    "        out += shortcut\n",
    "        out = self.relu2.forward(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = self.relu2.backward(dout)\n",
    "\n",
    "        dshortcut = dout.copy()\n",
    "        dmain = dout.copy()\n",
    "\n",
    "        dmain = self.bn2.backward(dmain)\n",
    "        dmain = self.conv2.backward(dmain)\n",
    "\n",
    "        dmain = self.relu1.backward(dmain)\n",
    "        dmain = self.bn1.backward(dmain)\n",
    "        dmain = self.conv1.backward(dmain)\n",
    "\n",
    "        if not self.equal_in_out:\n",
    "            dshortcut = self.bn_shortcut.backward(dshortcut)\n",
    "            dshortcut = self.shortcut.backward(dshortcut)\n",
    "\n",
    "        dx = dmain + dshortcut\n",
    "        return dx\n",
    "\n",
    "\n",
    "class ResNet20:\n",
    "    def __init__(self, input_dim=(3, 32, 32), num_classes=100):\n",
    "        self.params = []\n",
    "        self.trainable_layers = []\n",
    "\n",
    "        self.conv1 = Convolution(\n",
    "            W=np.random.randn(16, 3, 3, 3) * np.sqrt(2. / 3),\n",
    "            b=np.zeros(16),\n",
    "            stride=1,\n",
    "            pad=1\n",
    "        )\n",
    "        self.bn1 = BatchNormalization(gamma=np.ones(16), beta=np.zeros(16))\n",
    "        self.relu1 = Relu()\n",
    "\n",
    "        self.layer1 = [ResidualBlock(16, 16, stride=1) for _ in range(3)]\n",
    "        self.layer2 = [ResidualBlock(16 if i == 0 else 32, 32, stride=2 if i == 0 else 1) for i in range(3)]\n",
    "        self.layer3 = [ResidualBlock(32 if i == 0 else 64, 64, stride=2 if i == 0 else 1) for i in range(3)]\n",
    "\n",
    "        self.fc = Affine(W=np.random.randn(64, num_classes) * np.sqrt(2. / 64), b=np.zeros(num_classes))\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        self.input = x\n",
    "\n",
    "        out = self.conv1.forward(x)\n",
    "        out = self.bn1.forward(out, train_flg)\n",
    "        out = self.relu1.forward(out)\n",
    "\n",
    "        for block in self.layer1:\n",
    "            out = block.forward(out, train_flg)\n",
    "        for block in self.layer2:\n",
    "            out = block.forward(out, train_flg)\n",
    "        for block in self.layer3:\n",
    "            out = block.forward(out, train_flg)\n",
    "\n",
    "        self.feature_map = out\n",
    "\n",
    "        N, C, H, W = out.shape\n",
    "        out = out.mean(axis=(2, 3))\n",
    "\n",
    "        self.pooled = out\n",
    "        out = self.fc.forward(out)\n",
    "        return out\n",
    "\n",
    "    def predict(self, x, batch_size=100):\n",
    "        y_list = []\n",
    "        for i in range(0, x.shape[0], batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            y_batch = self.forward(x_batch, train_flg=False)\n",
    "            y_list.append(y_batch)\n",
    "        return np.concatenate(y_list, axis=0)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.forward(x, train_flg=True)\n",
    "        return cross_entropy_error(softmax(y), t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        acc = 0.0\n",
    "        total = x.shape[0]\n",
    "        for i in range(0, total, batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            t_batch = t[i:i+batch_size]\n",
    "\n",
    "            y = self.predict(x_batch)\n",
    "            y = np.argmax(y, axis=1)\n",
    "\n",
    "            if t.ndim != 1:\n",
    "                t_batch = np.argmax(t_batch, axis=1)\n",
    "\n",
    "            acc += np.sum(y == t_batch)\n",
    "\n",
    "        return acc / total\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = self.fc.backward(dout)\n",
    "        dout = dout.reshape(self.feature_map.shape[0], self.feature_map.shape[1], 1, 1)\n",
    "        dout = dout.repeat(self.feature_map.shape[2], axis=2).repeat(self.feature_map.shape[3], axis=3)\n",
    "\n",
    "        for block in reversed(self.layer3):\n",
    "            dout = block.backward(dout)\n",
    "        for block in reversed(self.layer2):\n",
    "            dout = block.backward(dout)\n",
    "        for block in reversed(self.layer1):\n",
    "            dout = block.backward(dout)\n",
    "\n",
    "        dout = self.relu1.backward(dout)\n",
    "        dout = self.bn1.backward(dout)\n",
    "        dout = self.conv1.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a77d25-72c7-41c6-9ce1-3acbaf4cd114",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## weight, bias 값 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5065933e-600e-437b-8774-2309a9f759e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model, weights):\n",
    "    idx = 0\n",
    "    # layer1\n",
    "    for i in range(3):\n",
    "        block = model.layer1[i]\n",
    "        block.conv1.W = weights[f'{idx}_W']\n",
    "        block.conv1.b = weights[f'{idx}_b']\n",
    "        idx += 1\n",
    "        block.conv2.W = weights[f'{idx}_W']\n",
    "        block.conv2.b = weights[f'{idx}_b']\n",
    "        idx += 1\n",
    "\n",
    "    # layer2\n",
    "    for i in range(3):\n",
    "        block = model.layer2[i]\n",
    "        block.conv1.W = weights[f'{idx}_W']\n",
    "        block.conv1.b = weights[f'{idx}_b']\n",
    "        idx += 1\n",
    "        block.conv2.W = weights[f'{idx}_W']\n",
    "        block.conv2.b = weights[f'{idx}_b']\n",
    "        idx += 1\n",
    "        if not block.equal_in_out:\n",
    "            block.shortcut.W = weights[f'{idx}_W']\n",
    "            block.shortcut.b = weights[f'{idx}_b']\n",
    "            idx += 1\n",
    "\n",
    "    # layer3\n",
    "    for i in range(3):\n",
    "        block = model.layer3[i]\n",
    "        block.conv1.W = weights[f'{idx}_W']\n",
    "        block.conv1.b = weights[f'{idx}_b']\n",
    "        idx += 1\n",
    "        block.conv2.W = weights[f'{idx}_W']\n",
    "        block.conv2.b = weights[f'{idx}_b']\n",
    "        idx += 1\n",
    "        if not block.equal_in_out:\n",
    "            block.shortcut.W = weights[f'{idx}_W']\n",
    "            block.shortcut.b = weights[f'{idx}_b']\n",
    "            idx += 1\n",
    "\n",
    "    # fc\n",
    "    model.fc.W = weights['fc_W']\n",
    "    model.fc.b = weights['fc_b']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c00d13e-1bd8-4ae6-bf9f-e74189e604ab",
   "metadata": {},
   "source": [
    "## 모델 출력 구하기(test data에 대한  예측)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9af6b4f-3507-4df2-857a-3308dfaa4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet20() \n",
    "load_weights(model, data['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da692f0-96c2-4145-9d0f-c1143f788763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_logits = model.predict(x_test)\n",
    "softmax_output = softmax(test_logits) \n",
    "\n",
    "##valid에 대해서 하기\n",
    "test_logits = model.predict(x_val)\n",
    "softmax_output = softmax(test_logits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56c0aedf-3750-4782-b215-4deffaa448f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fine accuracy: 0.0153\n"
     ]
    }
   ],
   "source": [
    "acc_test_fine = accuracy(softmax_output, y_test)\n",
    "print(f\"Test fine accuracy: {acc_test_fine:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e218ae7f-c0c9-4a19-a4a8-6c236e7ced16",
   "metadata": {},
   "source": [
    "## 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d4191dd-2298-497c-8662-346687d1ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] predict fine label:   60\n",
      "    true fine label:      49\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[1] predict fine label:   60\n",
      "    true fine label:      33\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[2] predict fine label:   60\n",
      "    true fine label:      72\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    0\n",
      "\n",
      "[3] predict fine label:   60\n",
      "    true fine label:      51\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    4\n",
      "\n",
      "[4] predict fine label:   60\n",
      "    true fine label:      71\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[5] predict fine label:   39\n",
      "    true fine label:      92\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[6] predict fine label:   39\n",
      "    true fine label:      15\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    11\n",
      "\n",
      "[7] predict fine label:   60\n",
      "    true fine label:      14\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    7\n",
      "\n",
      "[8] predict fine label:   60\n",
      "    true fine label:      23\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[9] predict fine label:   39\n",
      "    true fine label:      0\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    4\n",
      "\n",
      "[10] predict fine label:   39\n",
      "    true fine label:      71\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    10\n",
      "\n",
      "[11] predict fine label:   39\n",
      "    true fine label:      75\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    12\n",
      "\n",
      "[12] predict fine label:   33\n",
      "    true fine label:      81\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    19\n",
      "\n",
      "[13] predict fine label:   39\n",
      "    true fine label:      69\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    19\n",
      "\n",
      "[14] predict fine label:   60\n",
      "    true fine label:      40\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    5\n",
      "\n",
      "[15] predict fine label:   39\n",
      "    true fine label:      43\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    8\n",
      "\n",
      "[16] predict fine label:   39\n",
      "    true fine label:      92\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[17] predict fine label:   39\n",
      "    true fine label:      97\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    8\n",
      "\n",
      "[18] predict fine label:   39\n",
      "    true fine label:      70\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[19] predict fine label:   39\n",
      "    true fine label:      53\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    4\n",
      "\n",
      "[20] predict fine label:   39\n",
      "    true fine label:      70\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[21] predict fine label:   39\n",
      "    true fine label:      49\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    10\n",
      "\n",
      "[22] predict fine label:   39\n",
      "    true fine label:      75\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    12\n",
      "\n",
      "[23] predict fine label:   60\n",
      "    true fine label:      29\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    15\n",
      "\n",
      "[24] predict fine label:   60\n",
      "    true fine label:      21\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    11\n",
      "\n",
      "[25] predict fine label:   60\n",
      "    true fine label:      16\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    3\n",
      "\n",
      "[26] predict fine label:   39\n",
      "    true fine label:      39\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    5\n",
      "\n",
      "[27] predict fine label:   60\n",
      "    true fine label:      8\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    18\n",
      "\n",
      "[28] predict fine label:   60\n",
      "    true fine label:      8\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    18\n",
      "\n",
      "[29] predict fine label:   60\n",
      "    true fine label:      70\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##1.Argmx\n",
    "# 매핑 딕셔너리 불러오기\n",
    "fine_to_coarse = get_cifar100_fine_to_coarse_dict()\n",
    "\n",
    "# fine label 예측 → coarse label 매핑\n",
    "y_fine = np.argmax(softmax_output, axis=1)\n",
    "y_coarse_argmax = np.array([fine_to_coarse[f] for f in y_fine]) #이게 필요한건가?\n",
    "\n",
    "# --- 예시 출력 ---\n",
    "for a in range(30):\n",
    "    print(f\"[{a}] predict fine label:   {y_fine[a]}\")\n",
    "    print(f\"    true fine label:      {y_test[a]}\")\n",
    "    print(f\"    predict coarse label: {y_coarse_argmx[a]}\")\n",
    "    print(f\"    true coarse label:    {y_test_coarse[a]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e36a5183-5cc6-4367-a768-e5405c785501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] predict fine label:   60\n",
      "    true fine label:      49\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[1] predict fine label:   60\n",
      "    true fine label:      33\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[2] predict fine label:   60\n",
      "    true fine label:      72\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    0\n",
      "\n",
      "[3] predict fine label:   60\n",
      "    true fine label:      51\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    4\n",
      "\n",
      "[4] predict fine label:   60\n",
      "    true fine label:      71\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[5] predict fine label:   39\n",
      "    true fine label:      92\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[6] predict fine label:   39\n",
      "    true fine label:      15\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    11\n",
      "\n",
      "[7] predict fine label:   60\n",
      "    true fine label:      14\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    7\n",
      "\n",
      "[8] predict fine label:   60\n",
      "    true fine label:      23\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[9] predict fine label:   39\n",
      "    true fine label:      0\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    4\n",
      "\n",
      "[10] predict fine label:   39\n",
      "    true fine label:      71\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    10\n",
      "\n",
      "[11] predict fine label:   39\n",
      "    true fine label:      75\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    12\n",
      "\n",
      "[12] predict fine label:   33\n",
      "    true fine label:      81\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    19\n",
      "\n",
      "[13] predict fine label:   39\n",
      "    true fine label:      69\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    19\n",
      "\n",
      "[14] predict fine label:   60\n",
      "    true fine label:      40\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    5\n",
      "\n",
      "[15] predict fine label:   39\n",
      "    true fine label:      43\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    8\n",
      "\n",
      "[16] predict fine label:   39\n",
      "    true fine label:      92\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[17] predict fine label:   39\n",
      "    true fine label:      97\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    8\n",
      "\n",
      "[18] predict fine label:   39\n",
      "    true fine label:      70\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[19] predict fine label:   39\n",
      "    true fine label:      53\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    4\n",
      "\n",
      "[20] predict fine label:   39\n",
      "    true fine label:      70\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[21] predict fine label:   39\n",
      "    true fine label:      49\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    10\n",
      "\n",
      "[22] predict fine label:   39\n",
      "    true fine label:      75\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    12\n",
      "\n",
      "[23] predict fine label:   60\n",
      "    true fine label:      29\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    15\n",
      "\n",
      "[24] predict fine label:   60\n",
      "    true fine label:      21\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    11\n",
      "\n",
      "[25] predict fine label:   60\n",
      "    true fine label:      16\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    3\n",
      "\n",
      "[26] predict fine label:   39\n",
      "    true fine label:      39\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    5\n",
      "\n",
      "[27] predict fine label:   60\n",
      "    true fine label:      8\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    18\n",
      "\n",
      "[28] predict fine label:   60\n",
      "    true fine label:      8\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    18\n",
      "\n",
      "[29] predict fine label:   60\n",
      "    true fine label:      70\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##2.Entropy weigth\n",
    "# coarse softmax 분포 계산\n",
    "coarse_probs = entropy_based_coarse(softmax_output, fine_to_coarse)\n",
    "\n",
    "# coarse 예측 (argmax)\n",
    "y_fine = np.argmax(softmax_output, axis=1)\n",
    "y_coarse = np.argmax(coarse_probs, axis=1)\n",
    "#얘는 매핑할때 softmax 말고 다른 값이 필요한건가?\n",
    "\n",
    "# 정답 coarse label\n",
    "y_coarse_entropy = np.array([fine_to_coarse[f] for f in y_fine])\n",
    "\n",
    "# --- 예시 출력 ---\n",
    "for a in range(30):\n",
    "    print(f\"[{a}] predict fine label:   {y_fine[a]}\")\n",
    "    print(f\"    true fine label:      {y_test[a]}\")\n",
    "    print(f\"    predict coarse label: {y_coarse_entropy[a]}\")\n",
    "    print(f\"    true coarse label:    {y_test_coarse[a]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc927e35-1d6f-4b3b-8ad4-8f7c7926217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] predict fine label:   60\n",
      "     true fine label:      49\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    10\n",
      "\n",
      "[1] predict fine label:   60\n",
      "     true fine label:      33\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    10\n",
      "\n",
      "[2] predict fine label:   60\n",
      "     true fine label:      72\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    0\n",
      "\n",
      "[3] predict fine label:   60\n",
      "     true fine label:      51\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    4\n",
      "\n",
      "[4] predict fine label:   60\n",
      "     true fine label:      71\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    10\n",
      "\n",
      "[5] predict fine label:   39\n",
      "     true fine label:      92\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    2\n",
      "\n",
      "[6] predict fine label:   39\n",
      "     true fine label:      15\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    11\n",
      "\n",
      "[7] predict fine label:   60\n",
      "     true fine label:      14\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    7\n",
      "\n",
      "[8] predict fine label:   60\n",
      "     true fine label:      23\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    10\n",
      "\n",
      "[9] predict fine label:   39\n",
      "     true fine label:      0\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    4\n",
      "\n",
      "[10] predict fine label:   39\n",
      "     true fine label:      71\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    10\n",
      "\n",
      "[11] predict fine label:   39\n",
      "     true fine label:      75\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    12\n",
      "\n",
      "[12] predict fine label:   33\n",
      "     true fine label:      81\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    19\n",
      "\n",
      "[13] predict fine label:   39\n",
      "     true fine label:      69\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    19\n",
      "\n",
      "[14] predict fine label:   60\n",
      "     true fine label:      40\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    5\n",
      "\n",
      "[15] predict fine label:   39\n",
      "     true fine label:      43\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    8\n",
      "\n",
      "[16] predict fine label:   39\n",
      "     true fine label:      92\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    2\n",
      "\n",
      "[17] predict fine label:   39\n",
      "     true fine label:      97\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    8\n",
      "\n",
      "[18] predict fine label:   39\n",
      "     true fine label:      70\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    2\n",
      "\n",
      "[19] predict fine label:   39\n",
      "     true fine label:      53\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    4\n",
      "\n",
      "[20] predict fine label:   39\n",
      "     true fine label:      70\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    2\n",
      "\n",
      "[21] predict fine label:   39\n",
      "     true fine label:      49\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    10\n",
      "\n",
      "[22] predict fine label:   39\n",
      "     true fine label:      75\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    12\n",
      "\n",
      "[23] predict fine label:   60\n",
      "     true fine label:      29\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    15\n",
      "\n",
      "[24] predict fine label:   60\n",
      "     true fine label:      21\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    11\n",
      "\n",
      "[25] predict fine label:   60\n",
      "     true fine label:      16\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    3\n",
      "\n",
      "[26] predict fine label:   39\n",
      "     true fine label:      39\n",
      "     predict coarse label: 5\n",
      "     true coarse label:    5\n",
      "\n",
      "[27] predict fine label:   60\n",
      "     true fine label:      8\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    18\n",
      "\n",
      "[28] predict fine label:   60\n",
      "     true fine label:      8\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    18\n",
      "\n",
      "[29] predict fine label:   60\n",
      "     true fine label:      70\n",
      "     predict coarse label: 10\n",
      "     true coarse label:    2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##3.soft label\n",
    "#soft-label 기반 coarse 분포 계산\n",
    "coarse_probs = softlabel_coarse_mapping(softmax_output, fine_to_coarse)\n",
    "#coarse 예측\n",
    "y_coarse_softlabel = np.argmax(coarse_probs, axis=1)\n",
    "\n",
    "\n",
    "#acc_coarse = accuracy(coarse_probs, y_test_coarse)\n",
    "#print(f\"Soft-label 기반 coarse acc: {acc_coarse:.4f}\")\n",
    "\n",
    "for a in range(30):\n",
    "    print(f\"[{a}] predict fine label:   {y_fine[a]}\")\n",
    "    print(f\"     true fine label:      {y_test[a]}\")\n",
    "    print(f\"     predict coarse label: {y_coarse_softlabel[a]}\")\n",
    "    print(f\"     true coarse label:    {y_test_coarse[a]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16881cfa-2e63-4f1b-a82f-070ea663e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "##4.validation weight\n",
    "#Step 1. fine-class별 validation 정확도 계산 → fine_weight[100]\n",
    "#Step 2. softmax_output × fine_weight → weighted_softmax\n",
    "#Step 3. fine → coarse 그룹 합산 → coarse_probs_weighted\n",
    "#Step 4. argmax(coarse_probs_weighted) → coarse 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a85ddf56-ae6e-463f-818f-3ec35de7f1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] predict fine label:   60\n",
      "    true fine label:      49\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[1] predict fine label:   60\n",
      "    true fine label:      33\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[2] predict fine label:   60\n",
      "    true fine label:      72\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    0\n",
      "\n",
      "[3] predict fine label:   60\n",
      "    true fine label:      51\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    4\n",
      "\n",
      "[4] predict fine label:   60\n",
      "    true fine label:      71\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[5] predict fine label:   39\n",
      "    true fine label:      92\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[6] predict fine label:   39\n",
      "    true fine label:      15\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    11\n",
      "\n",
      "[7] predict fine label:   60\n",
      "    true fine label:      14\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    7\n",
      "\n",
      "[8] predict fine label:   60\n",
      "    true fine label:      23\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    10\n",
      "\n",
      "[9] predict fine label:   39\n",
      "    true fine label:      0\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    4\n",
      "\n",
      "[10] predict fine label:   39\n",
      "    true fine label:      71\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    10\n",
      "\n",
      "[11] predict fine label:   39\n",
      "    true fine label:      75\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    12\n",
      "\n",
      "[12] predict fine label:   33\n",
      "    true fine label:      81\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    19\n",
      "\n",
      "[13] predict fine label:   39\n",
      "    true fine label:      69\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    19\n",
      "\n",
      "[14] predict fine label:   60\n",
      "    true fine label:      40\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    5\n",
      "\n",
      "[15] predict fine label:   39\n",
      "    true fine label:      43\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    8\n",
      "\n",
      "[16] predict fine label:   39\n",
      "    true fine label:      92\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[17] predict fine label:   39\n",
      "    true fine label:      97\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    8\n",
      "\n",
      "[18] predict fine label:   39\n",
      "    true fine label:      70\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[19] predict fine label:   39\n",
      "    true fine label:      53\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    4\n",
      "\n",
      "[20] predict fine label:   39\n",
      "    true fine label:      70\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    2\n",
      "\n",
      "[21] predict fine label:   39\n",
      "    true fine label:      49\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    10\n",
      "\n",
      "[22] predict fine label:   39\n",
      "    true fine label:      75\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    12\n",
      "\n",
      "[23] predict fine label:   60\n",
      "    true fine label:      29\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    15\n",
      "\n",
      "[24] predict fine label:   60\n",
      "    true fine label:      21\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    11\n",
      "\n",
      "[25] predict fine label:   60\n",
      "    true fine label:      16\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    3\n",
      "\n",
      "[26] predict fine label:   39\n",
      "    true fine label:      39\n",
      "    predict coarse label: 5\n",
      "    true coarse label:    5\n",
      "\n",
      "[27] predict fine label:   60\n",
      "    true fine label:      8\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    18\n",
      "\n",
      "[28] predict fine label:   60\n",
      "    true fine label:      8\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    18\n",
      "\n",
      "[29] predict fine label:   60\n",
      "    true fine label:      70\n",
      "    predict coarse label: 10\n",
      "    true coarse label:    2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. fine accuracy 기반 weight 구하기\n",
    "fine_acc_weight = compute_fine_class_accuracy(y_fine, y_test)#여기 변수명 점검\n",
    "# 2. 가중 coarse 확률 분포 만들기\n",
    "coarse_probs_val_weight = validation_weighted_coarse(softmax_output, fine_acc_weight, fine_to_coarse)\n",
    "# 3. 예측\n",
    "y_coarse_valweight = np.argmax(coarse_probs_val_weight, axis=1)\n",
    "\n",
    "# --- 예시 출력 ---\n",
    "for a in range(30):\n",
    "    print(f\"[{a}] predict fine label:   {y_fine[a]}\")\n",
    "    print(f\"    true fine label:      {y_test[a]}\")\n",
    "    print(f\"    predict coarse label: {y_coarse_valweight[a]}\")\n",
    "    print(f\"    true coarse label:    {y_test_coarse[a]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe109f8-2f52-492a-a209-1b7b5c9d5ee7",
   "metadata": {},
   "source": [
    "## 매핑 기법 정확도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d5500455-8cb6-4ff2-b0fe-2bf7eb05876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Coarse Accuracy 비교\n",
      "1. Argmax 기반         : 0.06420\n",
      "2. Entropy-weighted    : 0.06420\n",
      "3. Soft-label 평균 기반: 0.06420\n",
      "4. Validation-weight 기반: 0.06420\n"
     ]
    }
   ],
   "source": [
    "#정답\n",
    "y_true_coarse = y_test_coarse\n",
    "\n",
    "#정확도 계산\n",
    "acc_coarse_argmax = accuracy(y_coarse_argmax, y_true_coarse)\n",
    "acc_coarse_entropy = accuracy(y_coarse_entropy, y_true_coarse)\n",
    "acc_coarse_softlabel = accuracy(y_coarse_softlabel, y_true_coarse)\n",
    "acc_coarse_valweight = accuracy(y_coarse_valweight, y_true_coarse)\n",
    "\n",
    "\n",
    "print(\"📊 Coarse Accuracy 비교\")\n",
    "print(f\"1. Argmax 기반         : {acc_coarse_argmax:.5f}\")\n",
    "print(f\"2. Entropy-weighted    : {acc_coarse_entropy:.5f}\")\n",
    "print(f\"3. Soft-label 평균 기반: {acc_coarse_softlabel:.5f}\")\n",
    "print(f\"4. Validation-weight 기반: {acc_coarse_valweight:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf69ffa-f690-4447-9b14-fd41a1de87e2",
   "metadata": {},
   "source": [
    "## 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b74c1-b1dd-41c9-b8ac-a5c68bfa1385",
   "metadata": {},
   "source": [
    "### 0.정확도 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc2e4b36-0b79-4613-bc29-74c5065df43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#라벨 형태, softmax 형태 둘다 가능\n",
    "def accuracy(pred_or_probs, y_true):\n",
    "    if pred_or_probs.ndim == 1:\n",
    "        pred = pred_or_probs  # 라벨 정확도\n",
    "    else:\n",
    "        pred = np.argmax(pred_or_probs, axis=1)  # softmax의 정확도\n",
    "    return np.mean(pred == y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1aa37-abe8-47f9-81af-315824f66823",
   "metadata": {},
   "source": [
    "### 1.단순 매핑 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a2be1b4-fb9a-479b-b0bf-0ae8767c1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##1. 단순 매핑\n",
    "def load_fine_to_coarse_from_train(data_dir='./cifar-100-python'):\n",
    "    with open(f\"{data_dir}/train\", 'rb') as f:\n",
    "        train_data = pickle.load(f, encoding='bytes')\n",
    "\n",
    "    fine_labels = train_data[b'fine_labels']\n",
    "    coarse_labels = train_data[b'coarse_labels']\n",
    "\n",
    "    fine_to_coarse = {}\n",
    "    for f, c in zip(fine_labels, coarse_labels):\n",
    "        if f not in fine_to_coarse:\n",
    "            fine_to_coarse[f] = c\n",
    "        else:\n",
    "            assert fine_to_coarse[f] == c, f\"Conflict: {f} → {fine_to_coarse[f]} vs {c}\"\n",
    "    \n",
    "    return fine_to_coarse\n",
    "\n",
    "\n",
    "\n",
    "#매핑 테이블\n",
    "def get_cifar100_fine_to_coarse_dict():\n",
    "    \"\"\"\n",
    "    CIFAR-100의 fine label (0~99)을 coarse label (0~19)로 매핑하는 딕셔너리를 반환\n",
    "    \"\"\"\n",
    "    fine_to_coarse = {\n",
    "     0:  4,  1:  1,  2: 14,  3:  8,  4:  0,\n",
    "     5:  6,  6:  7,  7:  7,  8: 18,  9:  3,\n",
    "    10:  3, 11: 14, 12:  9, 13: 18, 14:  7,\n",
    "    15: 11, 16:  3, 17:  9, 18:  7, 19: 11,\n",
    "    20:  6, 21: 11, 22:  5, 23: 10, 24:  7,\n",
    "    25:  6, 26: 13, 27: 15, 28:  3, 29: 15,\n",
    "    30:  0, 31: 11, 32:  1, 33: 10, 34: 12,\n",
    "    35: 14, 36: 16, 37:  9, 38: 11, 39:  5,\n",
    "    40:  5, 41: 19, 42:  8, 43:  8, 44: 15,\n",
    "    45: 13, 46: 14, 47: 17, 48: 18, 49: 10,\n",
    "    50: 16, 51:  4, 52: 17, 53:  4, 54:  2,\n",
    "    55:  0, 56: 17, 57:  4, 58: 18, 59: 17,\n",
    "    60: 10, 61:  3, 62:  2, 63: 12, 64: 12,\n",
    "    65: 16, 66: 12, 67:  1, 68:  9, 69: 19,\n",
    "    70:  2, 71: 10, 72:  0, 73:  1, 74: 16,\n",
    "    75: 12, 76:  9, 77: 13, 78: 15, 79: 13,\n",
    "    80: 16, 81: 19, 82:  2, 83:  4, 84:  6,\n",
    "    85: 19, 86:  5, 87:  5, 88:  8, 89: 19,\n",
    "    90: 18, 91:  1, 92:  2, 93: 15, 94:  6,\n",
    "    95:  0, 96: 17, 97:  8, 98: 14, 99: 13\n",
    "}\n",
    "    return fine_to_coarse\n",
    "\n",
    "\n",
    "def map_softmax_to_coarse(softmax_output, fine_to_coarse):\n",
    "    \"\"\"\n",
    "    softmax_output: shape (N, 100), softmax 확률 결과\n",
    "    fine_to_coarse: dict, fine label → coarse label 매핑\n",
    "    \n",
    "    return: pred_coarse: shape (N,), coarse label 예측 결과\n",
    "    \"\"\"\n",
    "    fine_pred = np.argmax(softmax_output, axis=1)  # shape (N,)\n",
    "    coarse_pred = np.array([fine_to_coarse[f] for f in fine_pred])  # shape (N,)\n",
    "    return coarse_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417eac4-2ff6-4c99-9d14-0c3c833fe97f",
   "metadata": {},
   "source": [
    "### 2.entropy weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "180aa393-95f1-49cf-8cb9-009965a3dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_based_coarse(softmax_output, fine_to_coarse, num_coarse=20):\n",
    "    \"\"\"\n",
    "    softmax 결과의 엔트로피를 기반으로 신뢰도를 추정하고,\n",
    "    coarse-class 확률로 변환하는 후처리 함수입니다.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    softmax_output : np.ndarray\n",
    "        shape (N, 100) — 모델의 fine-class softmax 출력\n",
    "    fine_to_coarse : dict\n",
    "        fine-class index (0~99) → coarse-class index (0~19) 매핑 딕셔너리\n",
    "    num_coarse : int\n",
    "        coarse 클래스 개수 (기본: 20)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    coarse_probs : np.ndarray\n",
    "        shape (N, 20) — 각 sample의 coarse-class 확률 분포\n",
    "    \"\"\"\n",
    "\n",
    "    N = softmax_output.shape[0]  # sample 개수\n",
    "    log100 = np.log(100)         # 최대 엔트로피 값 (정규화용)\n",
    "    coarse_probs = np.zeros((N, num_coarse))  # 결과 coarse 확률 초기화\n",
    "\n",
    "    for i in range(N):\n",
    "        # ① 해당 샘플의 softmax 벡터 (fine-class 확률)\n",
    "        fine_probs = softmax_output[i]  # shape (100,)\n",
    "\n",
    "        # ② entropy 계산 (불확실성 측정)\n",
    "        entropy = -np.sum(fine_probs * np.log(fine_probs + 1e-9))  # log(0) 방지\n",
    "\n",
    "        # ③ 신뢰도 계산: 확신이 높을수록 1에 가까움\n",
    "        confidence = 1 - (entropy / log100)\n",
    "\n",
    "        # ④ fine-class 확률에 confidence 곱하기 (확신도 기반 가중)\n",
    "        weighted_fine_probs = fine_probs * confidence  # shape (100,)\n",
    "\n",
    "        # ⑤ coarse-class 단위로 합산\n",
    "        for fine_idx, prob in enumerate(weighted_fine_probs):\n",
    "            coarse_idx = fine_to_coarse[fine_idx]\n",
    "            coarse_probs[i][coarse_idx] += prob\n",
    "\n",
    "    return coarse_probs  # shape (N, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64c14a-0fe0-42a9-adf2-014cbee3c89a",
   "metadata": {},
   "source": [
    "### 3. confidence 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6459151b-9f0c-46df-a6a8-e357ade5d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softlabel_coarse_mapping(fine_probs, fine_to_coarse_dict, num_coarse=20):\n",
    "    batch_size = fine_probs.shape[0]\n",
    "    coarse_probs = np.zeros((batch_size, num_coarse))\n",
    "\n",
    "    for fine_idx in range(100):\n",
    "        coarse_idx = fine_to_coarse_dict[fine_idx]\n",
    "        coarse_probs[:, coarse_idx] += fine_probs[:, fine_idx]\n",
    "    \n",
    "    return coarse_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f72c1-945f-477d-9581-0c152dab75ab",
   "metadata": {},
   "source": [
    "### validation weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d1c40fe-283b-4617-aee8-be2c14084d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fine_class_accuracy(pred_fine, true_fine, num_classes=100):\n",
    "    correct = np.zeros(num_classes)\n",
    "    total = np.zeros(num_classes)\n",
    "\n",
    "    for pf, tf in zip(pred_fine, true_fine):\n",
    "        total[tf] += 1\n",
    "        if pf == tf:\n",
    "            correct[tf] += 1\n",
    "\n",
    "    acc = correct / (total + 1e-9)  # avoid divide by 0\n",
    "    acc = acc / np.max(acc)        # normalize to [0, 1]\n",
    "    return acc  # shape (100,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90e85a8f-33ec-42da-8a55-a3fe35a268f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_weighted_coarse(softmax_output, fine_weight, fine_to_coarse, num_coarse=20):\n",
    "    weighted_fine = softmax_output * fine_weight[np.newaxis, :]  # shape (N, 100)\n",
    "    coarse_probs = np.zeros((softmax_output.shape[0], num_coarse))\n",
    "    \n",
    "    for f in range(100):\n",
    "        c = fine_to_coarse[f]\n",
    "        coarse_probs[:, c] += weighted_fine[:, f]\n",
    "    \n",
    "    return coarse_probs  # shape (N, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6688f-5821-4d17-a19a-c9fd4e074540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ANN)",
   "language": "python",
   "name": "ann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
